---
title: "Mineria_LAB_2"
author: "Joel Jaquez, Luis Gonzalez, Fabian Morales"
date: "2026-02-23"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
```{r}
library(cluster) 
library(fpc) 
library(NbClust) 
library(factoextra) 
library(hopkins) 
library(GGally) 
library(pheatmap)
library(hopkins)
```

```{r}
# Cargamos el dataset desde la carpeta Datos
movies <- read.csv("./Datos/movies_2026.csv")
```


# Clustering

## Ejercicio 1.1 Haga el preprocesamiento del dataset, explique qué variables no aportan información a la generación de grupos y por qué. Describa con qué variables calculará los grupos.
```{r}
# Seleccionar solo las variables numéricas que aportan información de éxito y magnitud
datos <- movies[, c("popularity", "budget", "revenue", "runtime", "voteCount", "voteAvg")]

# Quitamos valores nulos 
set.seed(123)
datos <- datos[complete.cases(datos),]

# Escalado los datos 
datos_scaled <- scale(datos)
```

Para la generación de los grupos, se descartaron las variables categóricas, fechas y de texto libre (como id, title, director, genres y releaseDate) , ya que los algoritmos de clustering se basan en el cálculo de distancias matemáticas (como la euclidiana) y su inclusión requeriría transformaciones que aumentarían drásticamente la dimensionalidad, introduciendo ruido y dificultando la interpretación de los clústeres. En su lugar, el agrupamiento se calculará utilizando exclusivamente variables numéricas que capturan la magnitud financiera y la recepción del público: popularity, budget, revenue, runtime, voteCount y voteAvg . Finalmente, estas variables seleccionadas fueron previamente escaladas para asegurar que las diferencias extremas de magnitud (por ejemplo, presupuestos en millones de dólares frente a calificaciones en una escala de 0 a 10) no dominen ni sesguen el cálculo de las distancias en el algoritmo.


## Ejercicio 1.2 Analice la tendencia al agrupamiento usando el estadístico de Hopkings y la VAT (Visual Assessment of cluster Tendency). Esta última hágala si es posible, teniendo en cuenta las dimensiones del conjunto de datos. Discuta sus resultados e impresiones.
```{r}
# Calcular el estadístico de Hopkins
set.seed(123)
valor_hopkins <- hopkins(datos_scaled)
print(paste("Valor de Hopkins:", valor_hopkins))
```
Para analizar la tendencia al agrupamiento, se calculó el estadístico de Hopkins utilizando la totalidad de los datos numéricos escalados, obteniendo un valor de 0.9999. Al estar este resultado sumamente alejado de 0.5 (y prácticamente en 1), se rechaza de forma contundente la hipótesis de aleatoriedad espacial, lo que confirma que las películas poseen una altísima tendencia natural a formar agrupaciones reales y estructuradas. Respecto a la Evaluación Visual de Tendencia (VAT), se tomó la decisión técnica de omitir su generación gráfica, esto se justifica por las altas dimensiones del conjunto de datos (19,883 registros), ya que procesar una matriz de distancias de tal magnitud saturaría la memoria computacional. Por lo tanto, la pertinencia de aplicar algoritmos de clustering queda plenamente respaldada y demostrada por la prueba de Hopkins.


## Ejercicio 1.3 Determine cuál es el número de grupos a formar más adecuado para los datos que está trabajando. Haga una gráfica de codo y explique la razón de la elección de la cantidad de clústeres con la que trabajará.
```{r}
# Generar la gráfica de codo usando factoextra
set.seed(123)
fviz_nbclust(datos_scaled, kmeans, method = "wss", k.max = 6) +
  labs(title = "Método del Codo para determinar K óptimo",
       x = "Número de clústeres (K)",
       y = "Suma total de cuadrados intra-clúster (WSS)") +
  theme_minimal()
```
Al observar la gráfica generada, se identifican descensos importantes en la varianza. Aunque existe una inflexión visible en $K=4$, se decidió trabajar con **K = 6** clústeres. La justificación de esta elección radica en que al llegar a 6 grupos, la varianza intra-clúster alcanza un nivel significativamente bajo (estabilizándose cerca de los 40,000 WSS). Esta cantidad de agrupaciones nos permitirá obtener una segmentación más fina y detallada de las películas, separando mejor los distintos nichos (como blockbusters extremos vs. películas independientes) sin caer en una sobredivisión de los datos.

## Ejercicio 1.4 Utilice los algoritmos k-medias y clustering jerárquico para agrupar. Compare los resultados generados por cada uno.

## Ejercicio 1.4 Utilice los algoritmos k-medias y clustering jerárquico para agrupar. Compare los resultados generados por cada uno.

```{r}
# Definir K óptimo
k_optimo <- 6 

# --- 1. ALGORITMO K-MEDIAS ---
set.seed(123)
# Aplicar k-medias a todo el dataset
km_res <- kmeans(datos_scaled, centers = k_optimo, nstart = 25)
datos$Cluster_KMeans <- as.factor(km_res$cluster)

# --- 2. CLUSTERING JERÁRQUICO ---
# Calcular matriz de distancias y clustering para todo el dataset
dist_mat <- dist(datos_scaled, method = "euclidean")
hc_res <- hclust(dist_mat, method = "ward.D2") 
hc_clusters <- cutree(hc_res, k = k_optimo)

# Guardar resultados en el dataset original
datos$Cluster_Jerarquico <- as.factor(hc_clusters)

# --- 3. COMPARACIÓN DE RESULTADOS ---
cat("--- Clústeres K-Medias ---\n")
print(table(datos$Cluster_KMeans))

cat("\n--- Clústeres Jerárquico ---\n")
print(table(datos$Cluster_Jerarquico))

cat("\n--- Matriz de Confusión (K-Medias vs Jerárquico) ---\n")
table(K_Medias = datos$Cluster_KMeans, Jerarquico = datos$Cluster_Jerarquico)
```
**Comparación de resultados:**
Al analizar la matriz de confusión y el tamaño de los clústeres, observamos que ambos algoritmos coinciden fuertemente en los extremos, pero difieren en la forma de segmentar la gran masa de datos promedio:

**Consenso en valores atípicos (Mega-éxitos):** Ambos modelos aislaron un grupo minúsculo casi idéntico. El clúster 3 de K-Medias y el clúster 6 del modelo Jerárquico agrupan a exactamente las mismas 7 películas. Por su tamaño, este grupo representa indudablemente los *outliers* más extremos del dataset (las películas con ingresos o popularidad fuera de escala).

**Grupos robustos bien definidos:** Existe una coincidencia directa y casi perfecta entre el clúster 2 de K-Medias y el clúster 2 del Jerárquico, compartiendo 6,324 películas. Esto indica que hay un perfil o nicho de películas matemáticamente muy claro que ambos algoritmos logran detectar sin problema.

**Diferencias en la masa central:** La mayor discrepancia ocurre en la zona de mayor densidad de datos. Por ejemplo, el clúster 5 de K-Medias agrupa a la gran mayoría de sus películas (8,977) dentro del clúster 3 del Jerárquico. Sin embargo, K-Medias fue más estricto al separar otras ~1,900 películas en su propio clúster 6, mientras que el Jerárquico prefirió aglomerarlas en su clúster 1. Esto ocurre porque K-Medias fuerza las agrupaciones en formas esféricas alrededor de sus centroides, mientras que el método aglomerativo de Ward (Jerárquico) une los puntos minimizando la varianza paso a paso.


## 1.5 Determine la calidad del agrupamiento hecho por cada algoritmo con el método de la silueta. Discuta los resultados.

```{r}
k <- 6

set.seed(123)
km <- kmeans(datos_scaled, centers = k, nstart = 25)


sil_km <- silhouette(km$cluster, dist(datos_scaled))
promedio_sil_km <- mean(sil_km[, "sil_width"])

cat("Silhouette promedio (K-means, K =", k, ") =", round(promedio_sil_km, 4), "\n")


fviz_silhouette(sil_km) +
  labs(title = paste("Silueta - K-means (K =", k, ")"))
```

El coeficiente de silueta promedio para el modelo K-means con K = 6 fue 0.5467 Dado que valores superiores a 0.5 representan una estructura de agrupamiento sólida, se concluye que el modelo logra identificar patrones diferenciados en los datos.

Al analizar los clústeres individualmente, se observa que algunos presentan una separación muy alta mientras que otros muestran valores más bajos, lo que sugiere cierto grado de solapamiento. No obstante, el comportamiento global del modelo es adecuado y consistente con la segmentación planteada.

## 1.6 Interprete los grupos basado en el conocimiento que tiene de los datos. Recuerde investigar las medidas de tendencia central de las variables continuas y las tablas de frecuencia de las variables categóricas pertenecientes a cada grupo. Identifique hallazgos interesantes debido a las agrupaciones y describa para qué le podría servir.

```{r}
datos_cluster <- datos
datos_cluster$cluster <- km$cluster
resumen_clusters <- datos_cluster %>%
  group_by(cluster) %>%
  summarise(
    n = n(),
    popularity_media = mean(popularity),
    budget_media = mean(budget),
    revenue_media = mean(revenue),
    runtime_media = mean(runtime),
    voteCount_media = mean(voteCount),
    voteAvg_media = mean(voteAvg)
  )

resumen_clusters



```


